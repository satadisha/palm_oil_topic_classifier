{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6e9b3b530dd44ea0866b77b1c995ec21":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dafa4841bf954620b1c679e0018808e4","IPY_MODEL_486be2768d144d138f52df4dacea029d","IPY_MODEL_1cb379e02d2c4c57960288969f49569d"],"layout":"IPY_MODEL_fba608dc39384f0dab86dc7e48b410dc"}},"dafa4841bf954620b1c679e0018808e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68b7381528be485ab5d135f9c0d39207","placeholder":"​","style":"IPY_MODEL_993896d07b6a46e38322bd4eb577409e","value":"Map: 100%"}},"486be2768d144d138f52df4dacea029d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_111d8c2874824208bf6061fd1f9a92ec","max":309,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d61f27ef2444c22bc429dd8ed9b7d01","value":309}},"1cb379e02d2c4c57960288969f49569d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cea765c59729463abba52335fed0fc3e","placeholder":"​","style":"IPY_MODEL_b26c3412bea64799a619352591239cee","value":" 309/309 [00:00&lt;00:00, 481.80 examples/s]"}},"fba608dc39384f0dab86dc7e48b410dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68b7381528be485ab5d135f9c0d39207":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"993896d07b6a46e38322bd4eb577409e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"111d8c2874824208bf6061fd1f9a92ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d61f27ef2444c22bc429dd8ed9b7d01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cea765c59729463abba52335fed0fc3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b26c3412bea64799a619352591239cee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fd0cdb6875a43e6959b4ed9e13bd555":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c671a3408fe4234857dfcec989cc4ac","IPY_MODEL_c753ee54bdfc4093a26365a8009b4f3a","IPY_MODEL_698fff31fac04d90a1c1cf5508f1d79f"],"layout":"IPY_MODEL_680c4fb3653841fa8123c8432039cd68"}},"1c671a3408fe4234857dfcec989cc4ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df0666051ce74caa8fa26692adb89cb0","placeholder":"​","style":"IPY_MODEL_634519c86a5c4b509a43341c6d58a0e7","value":"Map: 100%"}},"c753ee54bdfc4093a26365a8009b4f3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87c49b8462184b1b9053f82883bef4c5","max":78,"min":0,"orientation":"horizontal","style":"IPY_MODEL_292c2d4e4c8145c7b623f7676c2f16ae","value":78}},"698fff31fac04d90a1c1cf5508f1d79f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1526c46d51a54676bcb2b7b22551a486","placeholder":"​","style":"IPY_MODEL_d4adf9e7571b4627a2d5e272e07a07ec","value":" 78/78 [00:00&lt;00:00, 439.06 examples/s]"}},"680c4fb3653841fa8123c8432039cd68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df0666051ce74caa8fa26692adb89cb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"634519c86a5c4b509a43341c6d58a0e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87c49b8462184b1b9053f82883bef4c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"292c2d4e4c8145c7b623f7676c2f16ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1526c46d51a54676bcb2b7b22551a486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4adf9e7571b4627a2d5e272e07a07ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Pre-Trained Word Embeddings for Text Classification"],"metadata":{"id":"lahf6KvZympt"}},{"cell_type":"markdown","source":["# Imports/Installations"],"metadata":{"id":"ccOyI07MyolN"}},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"KHPPdnj2Wzz5","executionInfo":{"status":"ok","timestamp":1754061592261,"user_tz":300,"elapsed":9543,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"outputId":"3e04f3c2-60a0-4ae0-e17d-39e66e7a28da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.34.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.7.14)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install transformers\n","!pip install -U datasets"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"xO5E_RiCW8RV","executionInfo":{"status":"ok","timestamp":1754061592694,"user_tz":300,"elapsed":430,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"outputId":"18a6bc39-d300-4f17-cedc-a62a1f4f6a3a"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from collections import defaultdict, Counter\n","import json\n","import numpy as np\n","import torch\n","import pandas as pd\n","\n","from matplotlib import pyplot as plt\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from datasets import load_dataset, DatasetDict\n","from torch.utils.data import DataLoader\n","from transformers import DistilBertConfig, DistilBertTokenizer, DistilBertForSequenceClassification, DistilBertModel\n","from transformers import get_linear_schedule_with_warmup\n","from tqdm.notebook import tqdm\n","from torch.optim import AdamW\n","from transformers import set_seed\n","from sklearn.metrics import accuracy_score, f1_score\n","from datasets import load_dataset, DatasetDict, Dataset\n","from torch.utils.data import DataLoader"],"metadata":{"id":"RjMDjd7tsgf7","executionInfo":{"status":"ok","timestamp":1754061592697,"user_tz":300,"elapsed":3,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":["# Loading and formatting CSVs"],"metadata":{"id":"9MqIs-u9zELg"}},{"cell_type":"code","source":["# OLD 60/20/20 DATA SPLIT\n","\n","# df = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Data/Labeled Data/BERTopic_results.csv')\n","# test = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Data/Labeled Data/BERTopic_TEST.csv')\n","# train = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Data/Labeled Data/BERTopic_TRAIN.csv')\n","# validation = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Data/Labeled Data/BERTopic_VAL.csv')\n","\n","# # turning into hugging face format\n","# test = Dataset.from_pandas(test)\n","# train = Dataset.from_pandas(train)\n","# validation = Dataset.from_pandas(validation)"],"metadata":{"id":"Hm8oX_37BFTk","executionInfo":{"status":"ok","timestamp":1754061592700,"user_tz":300,"elapsed":2,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Data/Labeled Data/BERTopic_results.csv')\n","# test = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Data/Labeled Data/BERTopic_TEST.csv')\n","train = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Text Classification Models/Classification Data/Base/BERTopic_TRAIN_80.csv')\n","validation = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Text Classification Models/Classification Data/Base/BERTopic_VAL_20.csv')\n","\n","# turning into hugging face format\n","# test = Dataset.from_pandas(test)\n","train = Dataset.from_pandas(train)\n","validation = Dataset.from_pandas(validation)"],"metadata":{"id":"8v2Iw3AJy0us","executionInfo":{"status":"ok","timestamp":1754061592702,"user_tz":300,"elapsed":1,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["word_counts = df['Text'].astype(str).apply(lambda x: len(x.split()))\n","\n","max_words = word_counts.max()\n","min_words = word_counts.min()\n","mean_words = word_counts.mean()\n","\n","print(f\"Max words in summary: {max_words}\")\n","print(f\"Min words in summary: {min_words}\")\n","print(f\"Mean words in summary: {mean_words}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BBIFsAU_y2S","executionInfo":{"status":"ok","timestamp":1754061592709,"user_tz":300,"elapsed":5,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"outputId":"f7807399-c8f6-4226-e9b8-499d0ce60a9a"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Max words in summary: 677\n","Min words in summary: 3\n","Mean words in summary: 40.064599483204134\n"]}]},{"cell_type":"markdown","source":["# Dataset Tokenization"],"metadata":{"id":"oZtG8HV3zRWg"}},{"cell_type":"markdown","source":["## Example Tokenization"],"metadata":{"id":"z0y1z2eezZmz"}},{"cell_type":"code","source":["name = \"distilbert-base-cased\"  # Remove the \"distilbert/\" prefix\n","tokenizer = DistilBertTokenizer.from_pretrained(name)\n","\n","sample_input = \"We want to use a pretrained tokenizer.\"\n","tokenized_inputs = tokenizer(sample_input,\n","                             return_tensors=\"pt\",\n","                             padding=True,\n","                             truncation=True,\n","                             max_length=512)\n","print(tokenized_inputs[\"input_ids\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQLD56MazLeH","executionInfo":{"status":"ok","timestamp":1754061592997,"user_tz":300,"elapsed":274,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"outputId":"bb683d60-805b-4fbd-980f-db67c75899e2"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  101,  1284,  1328,  1106,  1329,   170,  3073,  4487,  9044, 22559,\n","         17260,   119,   102]])\n"]}]},{"cell_type":"markdown","source":["We will use the function that we use to test the tokenizer on a single input. We will also split our data into batches of 128."],"metadata":{"id":"e1E0GoSYzhpM"}},{"cell_type":"code","source":["# NOT SURE WHAT MAX LENGTH TO USE?"],"metadata":{"id":"-prZx_O8t9uk","executionInfo":{"status":"ok","timestamp":1754061592998,"user_tz":300,"elapsed":8,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":["## Tokenized Train Dataset"],"metadata":{"id":"kc5-wLu3z8Px"}},{"cell_type":"code","source":["tokenizer_length = 512"],"metadata":{"id":"RQijzLU729kG","executionInfo":{"status":"ok","timestamp":1754061592999,"user_tz":300,"elapsed":6,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n","\n","# Apply tokenization using map\n","tokenized_train = train.map(\n","    lambda example: tokenizer(example['Text'],\n","                             padding=\"max_length\",\n","                             truncation=True,\n","                             max_length=tokenizer_length)  # not sure what length to use\n",")\n","\n","# Remove the original text column (we don't need it after tokenization)\n","tokenized_train = tokenized_train.remove_columns(['Text'])\n","\n","# Rename 'Dominant_Topic' to 'labels' (standard for transformers)\n","tokenized_train = tokenized_train.rename_column(\"Dominant_Topic\", \"labels\")\n","\n","# Step 4: Set format to torch tensors\n","tokenized_train.set_format(\"torch\")\n","\n","# Check the results\n","print(\"Tokenized dataset features:\", tokenized_train.column_names)\n","print(\"Dataset size:\", len(tokenized_train))\n","print(\"\\nSample data shapes:\")\n","#print(f\"- input_ids: {tokenized_train[0]['input_ids'].shape}\")\n","print(f\"- attention_mask: {tokenized_train[0]['attention_mask'].shape}\")\n","print(f\"- labels: {tokenized_train[0]['labels']}\")\n","print(f\"- labels type: {type(tokenized_train[0]['labels'])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":170,"referenced_widgets":["6e9b3b530dd44ea0866b77b1c995ec21","dafa4841bf954620b1c679e0018808e4","486be2768d144d138f52df4dacea029d","1cb379e02d2c4c57960288969f49569d","fba608dc39384f0dab86dc7e48b410dc","68b7381528be485ab5d135f9c0d39207","993896d07b6a46e38322bd4eb577409e","111d8c2874824208bf6061fd1f9a92ec","1d61f27ef2444c22bc429dd8ed9b7d01","cea765c59729463abba52335fed0fc3e","b26c3412bea64799a619352591239cee"]},"id":"kfQETJGOzh05","executionInfo":{"status":"ok","timestamp":1754061594371,"user_tz":300,"elapsed":1375,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"outputId":"77310bbd-b7c3-459d-e484-d4a1839190b7"},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/309 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e9b3b530dd44ea0866b77b1c995ec21"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenized dataset features: ['labels', 'input_ids', 'attention_mask']\n","Dataset size: 309\n","\n","Sample data shapes:\n","- attention_mask: torch.Size([512])\n","- labels: 3\n","- labels type: <class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["tokenized_train['labels'][5]"],"metadata":{"id":"WzSqTjyk-qbK","executionInfo":{"status":"ok","timestamp":1754061594394,"user_tz":300,"elapsed":22,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"17ccab54-7107-4af0-e13b-28b9b2d19a15"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0)"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","source":["## Tokenized Test Dataset"],"metadata":{"id":"7nc1jlHr0BTg"}},{"cell_type":"code","source":["# # Apply the same process to your test set\n","# tokenized_test = test.map(\n","#     lambda example: tokenizer(example['Text'],\n","#                              padding=\"max_length\",\n","#                              truncation=True,\n","#                              max_length=tokenizer_length)\n","# )\n","\n","# tokenized_test = tokenized_test.remove_columns(['Text'])\n","# tokenized_test = tokenized_test.rename_column(\"Dominant_Topic\", \"labels\")\n","# tokenized_test.set_format(\"torch\")\n","\n","# print(\"Test dataset size:\", len(tokenized_test))"],"metadata":{"id":"hit2Ksg-0A2L","executionInfo":{"status":"ok","timestamp":1754061594396,"user_tz":300,"elapsed":1,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["# tokenized_test['labels']"],"metadata":{"id":"-5zGmNQTUjsK","executionInfo":{"status":"ok","timestamp":1754061594438,"user_tz":300,"elapsed":30,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":["## Tokenized Validation Dataset"],"metadata":{"id":"yEDzcfm40IDD"}},{"cell_type":"code","source":["# Apply the same process to your test set\n","tokenized_validation = validation.map(\n","    lambda example: tokenizer(example['Text'],\n","                             padding=\"max_length\",\n","                             truncation=True,\n","                             max_length=tokenizer_length)\n",")\n","\n","tokenized_validation = tokenized_validation.remove_columns(['Text'])\n","tokenized_validation = tokenized_validation.rename_column(\"Dominant_Topic\", \"labels\")\n","tokenized_validation.set_format(\"torch\")\n","\n","print(\"Test dataset size:\", len(tokenized_validation))"],"metadata":{"id":"SdFbKJ060Kyo","executionInfo":{"status":"ok","timestamp":1754061595028,"user_tz":300,"elapsed":591,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["2fd0cdb6875a43e6959b4ed9e13bd555","1c671a3408fe4234857dfcec989cc4ac","c753ee54bdfc4093a26365a8009b4f3a","698fff31fac04d90a1c1cf5508f1d79f","680c4fb3653841fa8123c8432039cd68","df0666051ce74caa8fa26692adb89cb0","634519c86a5c4b509a43341c6d58a0e7","87c49b8462184b1b9053f82883bef4c5","292c2d4e4c8145c7b623f7676c2f16ae","1526c46d51a54676bcb2b7b22551a486","d4adf9e7571b4627a2d5e272e07a07ec"]},"outputId":"881871f5-dd1d-42f6-8501-457188e743a4"},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/78 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fd0cdb6875a43e6959b4ed9e13bd555"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test dataset size: 78\n"]}]},{"cell_type":"markdown","source":["## Check Tokenization on train and test"],"metadata":{"id":"Jz58ylJW0R42"}},{"cell_type":"code","source":["#lets check our tokenization for a few samples\n","tokenized_train[0:2]"],"metadata":{"id":"lAPImgA30TSV","executionInfo":{"status":"ok","timestamp":1754061595070,"user_tz":300,"elapsed":31,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"095dd60b-d775-4ab3-c115-23e59f41d041"},"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'labels': tensor([3, 3]),\n"," 'input_ids': tensor([[ 101, 2448, 3186,  ...,    0,    0,    0],\n","         [ 101,  129, 1260,  ...,    0,    0,    0]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]])}"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["#lets check our tokenization for a few samples\n","# tokenized_test[0:2]"],"metadata":{"id":"Ff_viz6m0VWt","executionInfo":{"status":"ok","timestamp":1754061595108,"user_tz":300,"elapsed":36,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["tokenized_validation[0:2]"],"metadata":{"id":"vxFTkIQL0ZE8","executionInfo":{"status":"ok","timestamp":1754061595146,"user_tz":300,"elapsed":42,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a699161-0d15-410c-de31-470715aeaabd"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'labels': tensor([0, 1]),\n"," 'input_ids': tensor([[  101,  1672,  3756,  ...,     0,     0,     0],\n","         [  101, 16370,  4033,  ...,     0,     0,     0]]),\n"," 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","         [1, 1, 1,  ..., 0, 0, 0]])}"]},"metadata":{},"execution_count":94}]},{"cell_type":"markdown","source":["# Using DataLoader to Batchify data\n","Make sure to send your datasets to the Dataloader in order to segment your dataset into batches. Remember that we need batches to run our iterative optimization procedure which is typically some form of Mini-batch Gradient Descent.\n","\n","In the interest of time we want to finetune our model on a sample of the training set with 309 records instead of the entire 62K sample size"],"metadata":{"id":"vaABf7NQ0ccF"}},{"cell_type":"markdown","source":["## batch_size"],"metadata":{"id":"zwQFvswUwr6Q"}},{"cell_type":"code","source":["batch_size = 8"],"metadata":{"id":"GEKYDi9OvFDg","executionInfo":{"status":"ok","timestamp":1754061595147,"user_tz":300,"elapsed":7,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["train_dataset = tokenized_train.shuffle(seed=1111).select(range(305))\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n","eval_dataloader = DataLoader(tokenized_validation, batch_size=batch_size)"],"metadata":{"id":"PdN0FUh30dDQ","executionInfo":{"status":"ok","timestamp":1754061595148,"user_tz":300,"elapsed":5,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":96,"outputs":[]},{"cell_type":"markdown","source":["# Training and Validation\n","We have now gone through all the required preprocessing to prep the data for training. Instead of the Trainer module, it will be a good practice to initially write our own training loops so that we are mindful of all the steps that required for training neural networks.\n","\n","Other than our training and validation data we need to select:\n","\n","An optimizer to run backpropagation\n","A scheduler that sets a protocol for parameter updates at the end of a batch\n","We would also like to set a seed at the start of computation. This ensures that we are able to generate reproducicble results across multiple training sessions.\n","\n","We run validation at the end of each epoch.\n","\n","**At the end of this step we want to report the best validation loss obtained during training. We also want to save the model corresponding to the epoch that reported the best validation loss.**"],"metadata":{"id":"OKF9c9ro0fXf"}},{"cell_type":"code","source":["model_path = '/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Text Classification Models/DistilBERT_Saved_Models/DistilBERT '"],"metadata":{"id":"alRjbWoY2a4i","executionInfo":{"status":"ok","timestamp":1754061595149,"user_tz":300,"elapsed":5,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["from torch.nn.utils import clip_grad_norm_\n","set_seed(42)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","#model = DistilBertForSequenceClassification.from_pretrained(name, num_labels=6).to(device)\n","# Load config first, modify it, then load model\n","config = DistilBertConfig.from_pretrained(name)\n","config.dropout = 0.1  # This is the valid parameter for DistilBert\n","config.seq_classif_dropout = 0.1  # Classifier dropout\n","config.num_labels = 6\n","\n","model = DistilBertForSequenceClassification.from_pretrained(name, config=config).to(device)\n","\n","num_epochs = 20\n","# num_training_steps = len(train_dataloader)\n","# INSTEAD OF ABOVE USE THIS\n","optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.005, eps=1e-6)  # Halved LR\n","#optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n","\n","num_training_steps = len(train_dataloader) * num_epochs\n","lr_scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=int(0.05 * num_training_steps),  # 10% warmup\n","    num_training_steps=num_training_steps\n",")\n","#lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","# For Graph\n","# x_epochs = range(num_epochs)\n","x_epochs = []\n","y_train = []\n","y_val = []\n","\n","best_val_loss = float(\"inf\")\n","\n","# Early Stopping (Prevents Overfitting)\n","early_stopping = True\n","early_count = 0 # +1 every time validation loss doesnt improve\n","early_limit = 5\n","\n","progress_bar = tqdm(range(num_training_steps))\n","for epoch in range(num_epochs):\n","    x_epochs.append(epoch)\n","\n","    # training\n","    model.train()\n","    training_losses = []\n","    for batch_i, batch in enumerate(train_dataloader):\n","\n","        optimizer.zero_grad()\n","\n","        # copy input to device\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device, dtype=torch.long) # Convert labels to LongTensor and move to device\n","\n","        # output = model(**batch)\n","        output = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        training_loss = output.loss\n","        training_losses.append(training_loss.item())\n","\n","        #backprop and update params by taking an optimization step\n","        # IMPROVING THE MODEL\n","        output.loss.backward()\n","        clip_grad_norm_(model.parameters(), max_norm=1.0)  # ADD THIS LINE\n","        optimizer.step()\n","        lr_scheduler.step()\n","        progress_bar.update(1)\n","    print(f\"Epoch {epoch}\")\n","    print(\"Mean Training Loss\", np.mean(training_losses))\n","    y_train.append(np.mean(training_losses))\n","\n","    # validation\n","    val_loss = 0\n","    model.eval() #important to call because we dont want to collect gradients\n","    for batch_i, batch in enumerate(eval_dataloader):\n","        with torch.no_grad():\n","            # copy input to device\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device, dtype=torch.long) # Convert labels to LongTensor and move to device\n","            # output = model(**batch)\n","            output = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        val_loss += output.loss\n","\n","    avg_val_loss = val_loss / len(eval_dataloader)\n","    print(f\"Validation loss: {avg_val_loss}\")\n","    y_val.append(avg_val_loss.cpu())\n","\n","    # print(f\"Validation loss: {avg_val_loss}\")\n","    if avg_val_loss < best_val_loss:\n","        print(\"Saving checkpoint!\")\n","        early_count = 0 # Reset counter\n","        best_val_loss = avg_val_loss\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            # 'optimizer_state_dict': optimizer.state_dict(),\n","            'val_loss': best_val_loss,\n","            },\n","            f\"{model_path}best_model.pt\"\n","        )\n","    elif early_stopping:\n","        early_count += 1\n","\n","        if early_count == early_limit:\n","            print(f\"Validation loss has not improved for {early_count} iterations; Early Stopping.\")\n","            break\n","    print()"],"metadata":{"id":"YOZJHka90hcG","executionInfo":{"status":"error","timestamp":1754061595242,"user_tz":300,"elapsed":96,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}},"colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"124dead9-1c96-4c70-ffe7-18fe0c7e4e0e"},"execution_count":98,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-368211721.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\u001b[0m in \u001b[0;36mset_seed\u001b[0;34m(seed, deterministic)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# ^^ safe to call this function even if cuda is not available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}]},{"cell_type":"code","source":["plt.plot(x_epochs, y_val)\n","plt.plot(x_epochs, y_train)\n","plt.style.use('fivethirtyeight')\n","plt.title(\"Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Validation Loss\")"],"metadata":{"id":"NRgaDxmCvAkp","executionInfo":{"status":"aborted","timestamp":1754061595238,"user_tz":300,"elapsed":12605,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Modify the location per model\n","model_location = \"/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Text Classification Models/DistilBERT_Saved_Models/DistilBERT best_model.pt\"\n","checkpoint = torch.load(model_location)\n","# Recreate the model architecture\n","model = DistilBertForSequenceClassification.from_pretrained(\n","    \"distilbert-base-cased\",\n","    num_labels=6\n",")\n","# Recreate the model architecture\n","#model = AutoModelForSequenceClassification.from_pretrained(\n","#    \"distilbert-base-cased\",\n","#    num_labels=6\n","#)\n","# Load the saved weights\n","model.load_state_dict(checkpoint[\"model_state_dict\"])\n","model.to(device)\n","model.eval()"],"metadata":{"collapsed":true,"id":"wEgv0cnjuigj","executionInfo":{"status":"aborted","timestamp":1754061595239,"user_tz":300,"elapsed":12604,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Evaluate your model on Test Data**\n","\n","Now we use our finetuned model to evaluate the test set. We use performance metrics from `sklearn.metrics` to test the effectiveness of our model on unseen test data.\n","\n","In order to do that, run the finetuned model you have just saved on your test data and report the following performance metrics:\n","\n","\n","\n","*   Accuracy\n","*   F1 Score"],"metadata":{"id":"nx_kxGNw7ay8"}},{"cell_type":"code","source":["eval_dataloader = DataLoader(tokenized_validation, batch_size=len(tokenized_validation))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model.eval()\n","test_batch_logits = []\n","y_true = []\n","for batch_i, batch in enumerate(eval_dataloader):\n","    with torch.no_grad():\n","        # copy input to device\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].cpu().detach().numpy()\n","        # output = model(**batch)\n","        output = model(input_ids, attention_mask=attention_mask)\n","        test_batch_logits.append(output.logits)\n","        y_true.extend(labels)"],"metadata":{"id":"VsumZmDG7aTi","executionInfo":{"status":"aborted","timestamp":1754061595241,"user_tz":300,"elapsed":12605,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(test_batch_logits),len(eval_dataloader))\n","test_logits = torch.cat(test_batch_logits, dim=0)\n","\n","#sanity check -> dimension 0 of your logits tensor should be same as the size of the test dataset\n","print(test_logits.shape,len(tokenized_validation),len(y_true))"],"metadata":{"id":"oGEY2QKq7u8z","executionInfo":{"status":"aborted","timestamp":1754061595303,"user_tz":300,"elapsed":1,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Convert the logits to predicted labels\n","y_pred = torch.argmax(test_logits, dim = 1).cpu().numpy()\n","print(y_true[:20])\n","print(y_pred[:20])\n","\n","#sanity check: should have as many predictions as labels\n","assert len(y_pred)==len(y_true)"],"metadata":{"id":"KvFRL0nx7yqk","executionInfo":{"status":"aborted","timestamp":1754061595305,"user_tz":300,"elapsed":2,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## F1 & Accuracy Scores"],"metadata":{"id":"R-iQk4V5uceI"}},{"cell_type":"code","source":["print('F1 Score (macro):', f1_score(y_true, y_pred, average='macro'))\n","print('F1 Score (weighted):', f1_score(y_true, y_pred, average='weighted'))\n","print('F1 Score (micro):', f1_score(y_true, y_pred, average='micro'))\n","print('Accuracy Score:', accuracy_score(y_true, y_pred))"],"metadata":{"id":"UGiYv47k71F7","executionInfo":{"status":"aborted","timestamp":1754061595306,"user_tz":300,"elapsed":0,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_true, y_pred, target_names=['0','1','2','3','4','5']))"],"metadata":{"id":"UkOq07CqUHrS","executionInfo":{"status":"aborted","timestamp":1754061595326,"user_tz":300,"elapsed":1,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Predicting"],"metadata":{"id":"mdAnRN-ki8IC"}},{"cell_type":"code","source":["model_name = \"DistilBERT\""],"metadata":{"id":"a5MR7Gw1-6D4","executionInfo":{"status":"aborted","timestamp":1754061595329,"user_tz":300,"elapsed":1,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load new data for classification\n","new_data_path = '/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Data/NEW_grievances_formatted.csv'\n","new_df = pd.read_csv(new_data_path)\n","\n","print(f\"Loaded {len(new_df)} entries for classification\")\n","print(\"Columns in new data:\", new_df.columns.tolist())\n","\n","# Prepare the text data (assuming 'summary' column contains the text to classify)\n","# If your text column has a different name, change 'summary' below\n","text_column = 'Text'\n","\n","# Convert to Dataset format\n","new_dataset = Dataset.from_pandas(new_df[[text_column]])\n","\n","# Tokenize the new data\n","tokenized_new_data = new_dataset.map(\n","    lambda example: tokenizer(str(example[text_column]),  # Convert to string to handle NaN\n","                             padding=\"max_length\",\n","                             truncation=True,\n","                             max_length=tokenizer_length)\n",")\n","\n","# Set format to torch tensors\n","tokenized_new_data.set_format(\"torch\")\n","\n","# Create DataLoader for inference\n","inference_dataloader = DataLoader(tokenized_new_data, batch_size=batch_size)\n","\n","# Run inference\n","model.eval()   # LOAD BEST MSODEL\n","all_predictions = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(inference_dataloader, desc=\"Classifying\"):\n","        # Move batch to device\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        # Get model predictions\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","\n","        # Convert logits to predicted labels\n","        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n","        all_predictions.extend(predictions)\n","\n","\n","# Read Classification CSV\n","results_df = pd.read_csv('/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Text Classification Models/classified_grievances.csv')\n","results_df[f'{model_name}_label'] = all_predictions\n","\n","\n","print(f\"\\nClassification complete!\")\n","print(f\"Label distribution:\")\n","# Add Label\n","print(results_df[f'{model_name}_label'].value_counts().sort_index())\n","\n","output_path = '/content/gdrive/MyDrive/Group 3: palm oil topic classifier/Text Classification Models/classified_grievances.csv'\n","results_df.to_csv(output_path, index=False)\n","\n","print(\"\\nFirst 10 classified entries:\")\n","print(results_df[['summary', f'{model_name}_label']].head(10))"],"metadata":{"id":"4J18YZQ9mJqw","executionInfo":{"status":"aborted","timestamp":1754061595331,"user_tz":300,"elapsed":12681,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_df"],"metadata":{"id":"AM3nA-4W692T","executionInfo":{"status":"aborted","timestamp":1754061595336,"user_tz":300,"elapsed":3,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_map = {\n","    0: 'Failed Compensation/Land Rights',\n","    1: 'Environmental Impact',\n","    2: 'Administrative',\n","    3: 'Deforestation',\n","    4: 'Labour Rights',\n","    5: 'Illegal or Contaminated FFB'\n","}\n","\n","results_df[f'{model_name}_topic'] = results_df[f'{model_name}_label'].map(label_map)\n","results_df"],"metadata":{"id":"0WBq9XLemvRA","executionInfo":{"status":"aborted","timestamp":1754061595338,"user_tz":300,"elapsed":4,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","topic_counts = results_df['manual_label'].value_counts()\n","print(topic_counts)\n","\n","plt.figure(figsize=(10, 6))\n","topic_counts.plot(kind='bar', edgecolor='black')\n","plt.title('Number of Grievances per Topic')\n","plt.xlabel('Topic')\n","plt.ylabel('Count')\n","plt.xticks(rotation=45, ha='right')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"af7B4ypUqVKe","executionInfo":{"status":"aborted","timestamp":1754061595339,"user_tz":300,"elapsed":4,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Comparison between Manual Labels and Transforemers' labels"],"metadata":{"id":"cSZIM8ALCxg_"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Get counts\n","manual_counts = results_df['manual_label'].value_counts()\n","distilbert_counts = results_df['DistilBERT_label'].value_counts()\n","spanbert_counts = results_df['SpanBERT_label'].value_counts()\n","electra_counts = results_df['Electra_label'].value_counts()\n","\n","\n","combined_counts = pd.DataFrame({\n","    'Manual': manual_counts,\n","    'DistilBERT': distilbert_counts,\n","    'SpanBERT': spanbert_counts\n","}).fillna(0)\n","\n","combined_counts = combined_counts.sort_index()\n","\n","# Plot\n","combined_counts.plot(kind='bar', figsize=(12, 6), edgecolor='black')\n","plt.title('Number of Grievances per Topic: Manual vs DistilBERT vs SpanBERT')\n","plt.xlabel('Topic')\n","plt.ylabel('Count')\n","plt.xticks(rotation=45, ha='right')\n","plt.legend(title='Label')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"fCzHMGpyCIxV","executionInfo":{"status":"aborted","timestamp":1754061595341,"user_tz":300,"elapsed":12674,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Evaluation ---\n","true_labels = results_df['manual_label'].astype(int).values\n","pred_labels = np.array(all_predictions)\n","\n","print(\"\\nEvaluation on New Data:\")\n","print(\"F1 Score (macro):\", f1_score(true_labels, pred_labels, average='macro'))\n","print(\"F1 Score (weighted):\", f1_score(true_labels, pred_labels, average='weighted'))\n","print(\"F1 Score (micro):\", f1_score(true_labels, pred_labels, average='micro'))\n","print(\"Accuracy:\", accuracy_score(true_labels, pred_labels))\n","\n","# Classification Report\n","print(\"\\nClassification Report:\")\n","print(classification_report(true_labels, pred_labels, target_names=[\n","    'Failed Compensation/Land Rights',\n","    'Environmental Impact',\n","    'Administrative',\n","    'Deforestation',\n","    'Labour Rights',\n","    'Illegal or Contaminated FFB'\n","]))"],"metadata":{"id":"QWxuexvItDnI","executionInfo":{"status":"aborted","timestamp":1754061595343,"user_tz":300,"elapsed":12672,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(results_df[results_df['manual_label'] == 1])"],"metadata":{"id":"3LhFb1LpzYkq","executionInfo":{"status":"aborted","timestamp":1754061595344,"user_tz":300,"elapsed":12670,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(results_df[results_df['manual_label'] == 0])"],"metadata":{"id":"MSJa8Am2B43y","executionInfo":{"status":"aborted","timestamp":1754061595345,"user_tz":300,"elapsed":12669,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(results_df[results_df['manual_label'] == 2])"],"metadata":{"id":"aHnn-uM2B78J","executionInfo":{"status":"aborted","timestamp":1754061595394,"user_tz":300,"elapsed":12716,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(results_df[results_df['manual_label'] == 4])"],"metadata":{"id":"flQyO8zEB_PT","executionInfo":{"status":"aborted","timestamp":1754061595396,"user_tz":300,"elapsed":12715,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(results_df[results_df['manual_label'] == 5])"],"metadata":{"id":"5VMZ3D3xCAx-","executionInfo":{"status":"aborted","timestamp":1754061595398,"user_tz":300,"elapsed":12714,"user":{"displayName":"Юля Ігнатеску","userId":"16377904788529979610"}}},"execution_count":null,"outputs":[]}]}